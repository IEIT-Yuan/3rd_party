
## 1. 概述

基于llama.cpp（version：b1742）在Windows系统（CPU Only）上对源2.0-2B模型的适配。

由于源2.0模型结构与llama结构存在差异，针对源2.0模型（Yuan2.0-2B）模型LFA结构，进行如下修改：

- llama计算图中添加LFA结构，修改ggml_conv_1d逻辑，以适配源2.0，保证前后序列长度不变；
- llama计算图中添加q、k混合相关的逻辑；
- 修改IM2COL算子，修改数组的读取方式；
- 修改ADD算子，将卷积模块的输出进行转置，以适配后面的计算；
- 修改concat算子，以适配q、k混合的逻辑；
- 支持多线程推理，加速生成速率；

目前支持fp16精度模型的gguf文件转换，后续会持续进行其他精度的工作。

## 2. gguf文件的生成

```shell
python convert.py --model yuan2b-hf\yuan2-2B --outfile zh-models/Yuan2-2B-Februa-hf-GGUF.gguf
```

## 3. 编译
  - On Windows:

    1. Download the latest fortran version of [w64devkit](https://github.com/skeeto/w64devkit/releases).
    2. Extract `w64devkit` on your pc.
    3. Run `w64devkit.exe`.
    4. Use the `cd` command to reach the `llama.cpp` folder.
    5. From here you can run:
        ```bash
        make
        ```


## 4. 测试Demo

### <font color=#FFC125 >测试环境 </font> 

- python3.9 
- 11th Gen Intel(R) Core(TM) i5-1145G7 @2.60GHz 2.61GHz
- 8.00GB RAM 
- Windows 10专业版（21H1） 

### <font color=#FFC125 >测试方法 </font> 


```shell
main.exe -m D:\\llama-cpp\\llama.cpp\\zh-models\\Yuan2-2B-Februa-hf-GGUF.gguf -p "北京简介" -n 400  --top-k  5 --threads 4
```


### <font color=#FFC125 >测试效果 </font> 

```shell
llama_new_context_with_model: n_ctx      = 512
llama_new_context_with_model: freq_base  = 10000.0
llama_new_context_with_model: freq_scale = 1
llama_new_context_with_model: KV self size  =   96.00 MiB, K (f16):   48.00 MiB, V (f16):   48.00 MiB
llama_build_graph: non-view tensors processed: 628/820
llama_build_graph: ****************************************************************
llama_build_graph: not all non-view tensors have been processed with a callback
llama_build_graph: this can indicate an inefficiency in the graph implementation
llama_build_graph: build with LLAMA_OFFLOAD_DEBUG for more info
llama_build_graph: ref: https://github.com/ggerganov/llama.cpp/pull/3837
llama_build_graph: ****************************************************************
llama_new_context_with_model: compute buffer total size = 270.94 MiB
Model metadata: {'tokenizer.ggml.add_eos_token': 'true', 'tokenizer.ggml.padding_token_id': '77185', 'tokenizer.ggml.seperator_token_id': '77185', 'tokenizer.ggml.eos_token_id': '77185', 'general.architecture': 'llama', 'llama.context_length': '8192', 'general.name': 'E:\\ckpts\\yuan2b-hf', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '2048', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '64', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '77185', 'llama.block_count': '24', 'llama.attention.head_count_kv': '32', 'tokenizer.ggml.model': 'llama', 'general.file_type': '1'}
北京是中国的首都，是华北地区的中心城市。它是中国政治、文化和经济的中心，也是中国最大的城市之一。北京具有悠久的历史和丰富的文化遗产，包括长城、故宫、天坛等世界闻名的古迹，以及现代化的摩天大楼和购物中心。
北京也是中国的教育和科研中心，拥有众多高等院校和科研机构，为中国培养了许多杰出人才。此外，北京还是中国重要的商业和交通中心，拥有众多的商业区和购物中心。
北京还是一个旅游胜地，吸引着大量的国内外游客前来参观和旅游。著名的景点包括故宫博物院、颐和园、天坛公园、八达岭长城等。这些景点都有着独特的历史文化背景和壮观的自然风光，给人们带来了不同的体验。
总的来说，北京是一个历史悠久、文化底蕴丰富、旅游胜地众多的城市，值得一游。无论是对于艺术爱好者、历史文化爱好者还是自然探索者，北京都有着不可多得的体验。


llama_print_timings:        load time =     579.04 ms
llama_print_timings:      sample time =     126.74 ms /   193 runs   (    0.66 ms per token,  1522.81 tokens per second)
llama_print_timings: prompt eval time =     578.98 ms /     4 tokens (  144.74 ms per token,     6.91 tokens per second)
llama_print_timings:        eval time =   20562.87 ms /   192 runs   (  107.10 ms per token,     9.34 tokens per second)
llama_print_timings:       total time =   22961.55 ms

```
### <font color=#FFC125 >测试性能 </font> 


<table>
    <tr>
        <th rowspan="2">推理性能</th><th>GGUF格式（C++）</th><th>HF格式（Python）</th><th>加速比</th>
    </tr>
    <tr>
        <td align="center">9.16 tokens/s</td><td align="center">1.21 tokens/s</td><td align="center">7.57</td>
    </tr>
    <tr>
        <th rowspan="2">内存占用</th><th>GGUF格式（C++）</th><th>HF格式（Python）</th><th>内存占比（GGUF/HF）</th>
    </tr>
    <tr>
        <td align="center">~0.4 GB</td><td align="center">~8.6 GB</td><td align="center">4.65%</td>
    </tr>
</table>
